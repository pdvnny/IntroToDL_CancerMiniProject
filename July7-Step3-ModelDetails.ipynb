{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b161a6a9-2dc5-4cad-a721-8e4dbdf0d220",
   "metadata": {},
   "source": [
    "# Parker Dunn\n",
    "\n",
    "__Assignment for COURSERA: Introduction to Deep Learning (via CU Boulder)__  \n",
    "__Assignment:__ Week 3 - CNN Cancer Detection Kaggle Mini-Project\n",
    "\n",
    "\n",
    "## To be added to main file\n",
    "\n",
    "Forgot to push the most recent version of my script from home."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8db1da-1a6c-4618-9a3f-9f6066f1d3e8",
   "metadata": {},
   "source": [
    "## Section 3 - Model Architecture\n",
    "\n",
    "#### Plan\n",
    "\n",
    "Due to limited time and computing resources, I'll stick to a simple model. I plan to use the \"building block-style\" Covolution-Convolution-Pooling design pattern with probably no more than 4 repetitions of this pattern. Since we previously experimented with the development of neural network architecture, I am hoping to replicate a reliable NN structure from one of the example image classification models from the videos. In theory, the key features will be extracted by the convolution architecture and the NN structure from another image classification task can be successfully optimized for new features.\n",
    "\n",
    "Laid out below are my achitecture plans as well as some of the thoughts I have regarding the training of my CNN.\n",
    "\n",
    "__Design parameters and Hyperparameters__\n",
    "Decisions\n",
    "* I will use ReLU (hidden layers) and sigmoid (output layer) as activation functions. This is not a design parameter that I plan to vary this time.\n",
    "* I will primarily use 3x3xd convolutional filters\n",
    "* As an optimization method, I will stick to SGD, which I am most familiar with, and plant to incorporate momentum if possible with the Keras API.\n",
    "\n",
    "Hyperparameters\n",
    "* Learning rate\n",
    "    * Test: 0.01 | 0.001 | 0.0001 (3 values)\n",
    "* Momentum\n",
    "    * Test: 0.0 | 0.01 | 0.1 (3 values)\n",
    "* Number of epochs (i.e., how much training)\n",
    "\n",
    "Design\n",
    "* Number of [Conv-Conv-Pool] layers\n",
    "    - Test: 2, 3, 4\n",
    "* Number of filters to use\n",
    "* \n",
    "\n",
    "Potential ways to improve a struggling model\n",
    "* L2 regularization\n",
    "* Batch normalization\n",
    "\n",
    "I plan to use moderate training parameters at first (e.g. learning rate -> 0.001 and momentum -> 0.01) to experiment and narrow down some viable convolution designs.\n",
    "\n",
    "#### Step 3 - Part 1: Trying to find a repeatable way to create a CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7053585-d19f-44fb-a434-d11937346c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "#import numpy as np\n",
    "from helperfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9770fe55-2038-4f4e-95fc-90acb33aba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def partial_load_data(n):\n",
    "    # n == total number of images to load\n",
    "    # split == tuple with fraction of images for training and validation\n",
    "    \n",
    "    train_locs, ~, y_train_info = load_image_info()\n",
    "    \n",
    "    # Generate random set of indices\n",
    "    rand_idx = np.random.randint(0,200000,(1,n))\n",
    "    \n",
    "    X = np.zeros((n, 96, 96, 3))\n",
    "    X_IDs = []\n",
    "    \n",
    "    for i, ind in enumerate(rand_idx):\n",
    "        img_file = train_locs[ind]\n",
    "        img = io.imread(img_file)        # NOTE: io.imread() reads images in as numpy.ndarray\n",
    "        \n",
    "        #img = img.reshape(1,96*96,3)\n",
    "        \n",
    "        X[i,:,:,:] = img /255.0  # NOTE: MODIFYING ALL VALUES TO 0-1 SCALE!!!\n",
    "        \n",
    "        X_IDs.append(img_file[6:-4])\n",
    "    \n",
    "    return X, X_IDs, y_train_info\n",
    "\n",
    "def partial_train_val_split(split, X, y_info):\n",
    "    # generate indices for training and validations sets based on 'split'\n",
    "    \n",
    "    # separate X and y_info into separate datasets\n",
    "    \n",
    "    # return X_tr, y_tr, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f066a1-f82e-440b-9018-cc6e6fbacaec",
   "metadata": {},
   "source": [
    "__Inputs__\n",
    "* List of layers\n",
    "    - convolution layers -> need filter sizes too\n",
    "    - NN layers -> any regularization?\n",
    "\n",
    "__Outputs__\n",
    "* Model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8354c7aa-99c9-4756-befb-edb0c9498f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 94, 94, 24)        672       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 92, 92, 48)        10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 46, 46, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 44, 44, 64)        27712     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 42, 42, 96)        55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 21, 21, 96)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 42336)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 96)                4064352   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 48)                4656      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 4,163,249\n",
      "Trainable params: 4,163,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers_lst = [\"input\",\"conv\", \"maxpool\",\"conv\",\"conv\",\"maxpool\",\"flatten\",\"dense\",\"dense\",\"dense\"]\n",
    "layer_design = [\n",
    "    {\"filters\":24, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True, \"input_shape\":(96,96,3)},\n",
    "    {\"filters\":48, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True},\n",
    "    {\"pool_size\":(2,2)},\n",
    "    {\"filters\":64, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True},\n",
    "    {\"filters\":72, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True},\n",
    "    {\"pool_size\":(2,2)},\n",
    "    None,\n",
    "    {\"size\":96, \"activation\":'relu'},\n",
    "    {\"size\":48, \"activation\":'relu'},\n",
    "    {\"size\":1, \"activation\":'sigmoid'}]\n",
    "    \n",
    "\n",
    "    \n",
    "nn_architecture = [96, 48, 1] # completely guessed that these are reasonable numbers\n",
    "\n",
    "## BELOW CAN BE TURNED INTO A FUNCTION THAT TAKES THE PARAMETERS ABOVE AND\n",
    "#  TURNS THEM INTO A MODEL!\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "for (l, d) in zip(layers_lst, layer_design):\n",
    "    if l == \"input\":\n",
    "        model.add(layers.Conv2D(d[\"filters\"], d[\"kernel_size\"], padding=d[\"padding\"], use_bias=d[\"use_bias\"], input_shape=d[\"input_shape\"]))\n",
    "    elif l == \"conv\":\n",
    "        model.add(layers.Conv2D(d[\"filters\"], d[\"kernel_size\"], padding=d[\"padding\"], use_bias=d[\"use_bias\"]))\n",
    "    elif l == \"maxpool\":\n",
    "        model.add(layers.MaxPool2D(d[\"pool_size\"]))\n",
    "    elif l == \"flatten\":\n",
    "        model.add(layers.Flatten())\n",
    "    elif l == \"dense\":\n",
    "        model.add(layers.Dense(d[\"size\"], activation=d[\"activation\"]))\n",
    "    # elif l == \"output\":\n",
    "    #     model.add(layers.Dense(d[\"size\"], activation=d[\"activation\"])\n",
    "    else:\n",
    "        raise Exception(\"Invalid layer provided for the model\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d69415-c585-47ea-afdd-ca070dd9e52e",
   "metadata": {},
   "source": [
    "## New Section -> Working on some helper functions for testing model design\n",
    "\n",
    "I don't want to use all of the available images to do some preliminary testing of model designs. Therefore, I'll setup some specific functions for training and validating on a small subset of the images available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ccb8ae-d0d8-469c-8c73-d37e932be36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_ids, y_info = partial_load_data(3000)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

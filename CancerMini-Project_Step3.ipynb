{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1628d7aa-f085-4c32-b677-11a5a3441b44",
   "metadata": {},
   "source": [
    "# Parker Dunn\n",
    "\n",
    "__Assignment for COURSERA: Introduction to Deep Learning (via CU Boulder)__  \n",
    "__Assignment:__ Week 3 - CNN Cancer Detection Kaggle Mini-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb6ebe-f2ec-4a88-be60-c557bbb34435",
   "metadata": {},
   "source": [
    "## Section 3 - Model Architecture\n",
    "\n",
    "#### Plan\n",
    "\n",
    "Due to limited time and computing resources, I'll stick to a simple model. I plan to use the \"building block-style\" Covolution-Convolution-Pooling design pattern with probably no more than 4 repetitions of this pattern. Since we previously experimented with the development of neural network architecture, I am hoping to replicate a reliable NN structure from one of the example image classification models from the videos. In theory, the key features will be extracted by the convolution architecture and the NN structure from another image classification task can be successfully optimized for new features.\n",
    "\n",
    "Laid out below are my achitecture plans as well as some of the thoughts I have regarding the training of my CNN.\n",
    "\n",
    "__Design parameters and Hyperparameters__\n",
    "Decisions\n",
    "* I will use ReLU (hidden layers) and sigmoid (output layer) as activation functions. This is not a design parameter that I plan to vary this time.\n",
    "* I will primarily use 3x3xd convolutional filters\n",
    "* As an optimization method, I will stick to SGD, which I am most familiar with, and plant to incorporate momentum if possible with the Keras API.\n",
    "\n",
    "Hyperparameters\n",
    "* Learning rate\n",
    "    * Test: 0.01 | 0.001 | 0.0001 (3 values)\n",
    "* Momentum\n",
    "    * Test: 0.0 | 0.01 | 0.1 (3 values)\n",
    "* Number of epochs (i.e., how much training)\n",
    "\n",
    "Design\n",
    "* Number of [Conv-Conv-Pool] layers\n",
    "    - Test: 2, 3, 4\n",
    "* Number of filters to use\n",
    "\n",
    "Potential ways to improve a struggling model\n",
    "* L2 regularization\n",
    "* Batch normalization\n",
    "\n",
    "I plan to use moderate training parameters at first (e.g. learning rate -> 0.001 and momentum -> 0.01) to experiment and narrow down some viable convolution designs.\n",
    "\n",
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f28d1bc-a65b-45d4-9b37-3365a7820717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def partial_load_data(n):\n",
    "    # n == total number of images to load\n",
    "    # split == tuple with fraction of images for training and validation\n",
    "    \n",
    "    train_locs, test_locs, y_train_info = load_image_info()\n",
    "    \n",
    "    # Generate random set of indices\n",
    "    rand_idx = np.random.randint(0,200000,(1,n))\n",
    "    \n",
    "    X = np.zeros((n, 96, 96, 3))\n",
    "    X_IDs = []\n",
    "    \n",
    "    for i, ind in enumerate(rand_idx):\n",
    "        img_file = train_locs[ind]\n",
    "        img = io.imread(img_file)        # NOTE: io.imread() reads images in as numpy.ndarray\n",
    "        \n",
    "        #img = img.reshape(1,96*96,3)\n",
    "        \n",
    "        X[i,:,:,:] = img /255.0  # NOTE: MODIFYING ALL VALUES TO 0-1 SCALE!!!\n",
    "        \n",
    "        X_IDs.append(img_file[6:-4])\n",
    "    \n",
    "    return X, X_IDs, y_train_info\n",
    "\n",
    "def partial_train_val_split(X, y_info, split=(0.66, 0.34)):\n",
    "    # generate indices for training and validations sets based on 'split'\n",
    "    sz = len(X)\n",
    "    n_train, n_val = int(split * sz)\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    idx_train = rng.choice(range(sz), (n_train,), replace=False, shuffle=False)\n",
    "    idx_val = list(set(range(sz)) - set(idx_train))\n",
    "    \n",
    "    # separate X and y_info into separate datasets\n",
    "    \n",
    "    # return X_tr, y_tr, X_val, y_val\n",
    "    return 1, 2, 3, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795f97d-77f7-43ca-8089-e11b94130c99",
   "metadata": {},
   "source": [
    "___\n",
    "#### Step 3 - Part 1: Trying to find a repeatable way to create a CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60cde3b7-3430-4cd6-a0b6-783aa90854d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "#import numpy as np\n",
    "from helperfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428c1c9a-791d-4eaf-9f98-fc76fab369bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_lst = [\"input\",\"conv\", \"maxpool\",\"conv\",\"conv\",\"maxpool\",\"flatten\",\"dense\",\"dense\",\"dense\"]\n",
    "layer_design = [\n",
    "    {\"filters\":24, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True, \"input_shape\":(96,96,3)},\n",
    "    {\"filters\":48, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True},\n",
    "    {\"pool_size\":(2,2)},\n",
    "    {\"filters\":64, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True},\n",
    "    {\"filters\":72, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True},\n",
    "    {\"pool_size\":(2,2)},\n",
    "    None,\n",
    "    {\"size\":96, \"activation\":'relu'},\n",
    "    {\"size\":48, \"activation\":'relu'},\n",
    "    {\"size\":1, \"activation\":'sigmoid'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de44dac-77b2-457c-a4b8-d7fa5f681f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BELOW CAN BE TURNED INTO A FUNCTION THAT TAKES THE PARAMETERS ABOVE AND\n",
    "#  TURNS THEM INTO A MODEL!\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "for (l, d) in zip(layers_lst, layer_design):\n",
    "    if l == \"input\":\n",
    "        model.add(layers.Conv2D(d[\"filters\"], d[\"kernel_size\"], padding=d[\"padding\"], use_bias=d[\"use_bias\"], input_shape=d[\"input_shape\"]))\n",
    "    elif l == \"conv\":\n",
    "        model.add(layers.Conv2D(d[\"filters\"], d[\"kernel_size\"], padding=d[\"padding\"], use_bias=d[\"use_bias\"]))\n",
    "    elif l == \"maxpool\":\n",
    "        model.add(layers.MaxPool2D(d[\"pool_size\"]))\n",
    "    elif l == \"flatten\":\n",
    "        model.add(layers.Flatten())\n",
    "    elif l == \"dense\":\n",
    "        model.add(layers.Dense(d[\"size\"], activation=d[\"activation\"]))\n",
    "    # elif l == \"output\":\n",
    "    #     model.add(layers.Dense(d[\"size\"], activation=d[\"activation\"])\n",
    "    else:\n",
    "        raise Exception(\"Invalid layer provided for the model\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ccaf1d-2a4f-4a8d-888d-8b1062914be4",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### Step 3 - Part 2: Loading some image data and splitting into training and validation\n",
    "\n",
    "I don't want to use all of the available images to do some preliminary testing of model designs. Therefore, I'll setup some specific functions for training and validating on a small subset of the images available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821666eb-9d00-4733-bb65-2a95f89380fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_ids, y_info = partial_load_data(3000)\n",
    "\n",
    "\n",
    "X_tr, y_tr, X_val, y_val = partial_train_val_split(X, y_info)\n",
    "\n",
    "print(X_tr, y_tr, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

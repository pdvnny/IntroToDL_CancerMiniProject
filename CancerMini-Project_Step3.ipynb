{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1628d7aa-f085-4c32-b677-11a5a3441b44",
   "metadata": {},
   "source": [
    "# Parker Dunn\n",
    "\n",
    "__Assignment for COURSERA: Introduction to Deep Learning (via CU Boulder)__  \n",
    "__Assignment:__ Week 3 - CNN Cancer Detection Kaggle Mini-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb6ebe-f2ec-4a88-be60-c557bbb34435",
   "metadata": {},
   "source": [
    "## Section 3 - Model Architecture\n",
    "\n",
    "#### Plan\n",
    "\n",
    "Due to limited time and computing resources, I'll stick to a simple model. I plan to use the \"building block-style\" Covolution-Convolution-Pooling design pattern with probably no more than 4 repetitions of this pattern. Since we previously experimented with the development of neural network architecture, I am hoping to replicate a reliable NN structure from one of the example image classification models from the videos. In theory, the key features will be extracted by the convolution architecture and the NN structure from another image classification task can be successfully optimized for new features.\n",
    "\n",
    "Laid out below are my achitecture plans as well as some of the thoughts I have regarding the training of my CNN.\n",
    "\n",
    "__Design parameters and Hyperparameters__\n",
    "Decisions\n",
    "* I will use ReLU (hidden layers) and sigmoid (output layer) as activation functions. This is not a design parameter that I plan to vary this time.\n",
    "* I will primarily use 3x3xd convolutional filters\n",
    "* As an optimization method, I will stick to SGD, which I am most familiar with, and plant to incorporate momentum if possible with the Keras API.\n",
    "\n",
    "Hyperparameters\n",
    "* Learning rate\n",
    "    * Test: 0.01 | 0.001 | 0.0001 (3 values)\n",
    "* Momentum\n",
    "    * Test: 0.0 | 0.01 | 0.1 (3 values)\n",
    "* Number of epochs (i.e., how much training)\n",
    "\n",
    "Design\n",
    "* Number of [Conv-Conv-Pool] layers\n",
    "    - Test: 2, 3, 4\n",
    "* Number of filters to use\n",
    "\n",
    "Potential ways to improve a struggling model\n",
    "* L2 regularization\n",
    "* Batch normalization\n",
    "\n",
    "I plan to use moderate training parameters at first (e.g. learning rate -> 0.001 and momentum -> 0.01) to experiment and narrow down some viable convolution designs.\n",
    "\n",
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f28d1bc-a65b-45d4-9b37-3365a7820717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def partial_load_data(n):\n",
    "    # n == total number of images to load\n",
    "    # split == tuple with fraction of images for training and validation\n",
    "    \n",
    "    train_locs, test_locs, y_train_info = load_image_info()\n",
    "    \n",
    "    # Generate random set of indices\n",
    "    rand_idx = np.random.randint(0,200000,(n,))\n",
    "    #print(len(train_locs))\n",
    "    #print(rand_idx.shape)\n",
    "    \n",
    "    X = np.zeros((n, 96, 96, 3))\n",
    "    X_IDs = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        ind = rand_idx[i]\n",
    "        #print(i, ind)\n",
    "        img_file = train_locs[ind]\n",
    "        img = io.imread(img_file)        # NOTE: io.imread() reads images in as numpy.ndarray\n",
    "        \n",
    "        #img = img.reshape(1,96*96,3)\n",
    "        \n",
    "        X[i,:,:,:] = img /255.0  # NOTE: MODIFYING ALL VALUES TO 0-1 SCALE!!!\n",
    "        \n",
    "        X_IDs.append(img_file[6:-4])\n",
    "    \n",
    "    return X, X_IDs, y_train_info\n",
    "\n",
    "def partial_train_val_split(X, y_info, split=(0.66, 0.34)):\n",
    "    # generate indices for training and validations sets based on 'split'\n",
    "    sz = len(X)\n",
    "    n_train, n_val = [int(split[i] * sz) for i in range(len(split))]\n",
    "    print(n_train, n_val)\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    idx_train = rng.choice(range(sz), (n_train,), replace=False, shuffle=False)\n",
    "    idx_val = list(set(range(sz)) - set(idx_train))\n",
    "    \n",
    "    # separate X and y_info into separate datasets\n",
    "    X_tr = X[idx_train,:,:,:]\n",
    "    y_tr = y_info.iloc[idx_train,:].reset_index()\n",
    "    \n",
    "    X_val = X[idx_val,:,:,:]\n",
    "    y_val = y_info.iloc[idx_val,:].reset_index()\n",
    "    \n",
    "    # return X_tr, y_tr, X_val, y_val\n",
    "    return X_tr, y_tr, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795f97d-77f7-43ca-8089-e11b94130c99",
   "metadata": {},
   "source": [
    "___\n",
    "#### Step 3 - Part 1: Trying to find a repeatable way to create a CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60cde3b7-3430-4cd6-a0b6-783aa90854d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "#import numpy as np\n",
    "from helperfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428c1c9a-791d-4eaf-9f98-fc76fab369bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_lst = [\"input\",\"conv\", \"maxpool\",\"conv\",\"conv\",\"maxpool\",\"flatten\",\"dense\",\"dense\",\"dense\"]\n",
    "layer_design = [\n",
    "    {\"filters\":24, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True, \"input_shape\":(96,96,3)},\n",
    "    {\"filters\":48, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True},\n",
    "    {\"pool_size\":(2,2)},\n",
    "    {\"filters\":64, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True},\n",
    "    {\"filters\":72, \"kernel_size\":(3,3), \"padding\":\"valid\", \"data_format\":\"channels_last\", \"use_bias\":True},\n",
    "    {\"pool_size\":(2,2)},\n",
    "    None,\n",
    "    {\"size\":96, \"activation\":'relu'},\n",
    "    {\"size\":48, \"activation\":'relu'},\n",
    "    {\"size\":1, \"activation\":'sigmoid'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de44dac-77b2-457c-a4b8-d7fa5f681f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 94, 94, 24)        672       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 92, 92, 48)        10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 46, 46, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 64)        27712     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 42, 42, 72)        41544     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 72)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 31752)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 96)                3048288   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 48)                4656      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 3,133,337\n",
      "Trainable params: 3,133,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## BELOW CAN BE TURNED INTO A FUNCTION THAT TAKES THE PARAMETERS ABOVE AND\n",
    "#  TURNS THEM INTO A MODEL!\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "for (l, d) in zip(layers_lst, layer_design):\n",
    "    if l == \"input\":\n",
    "        model.add(layers.Conv2D(d[\"filters\"], d[\"kernel_size\"], padding=d[\"padding\"], use_bias=d[\"use_bias\"], input_shape=d[\"input_shape\"]))\n",
    "    elif l == \"conv\":\n",
    "        model.add(layers.Conv2D(d[\"filters\"], d[\"kernel_size\"], padding=d[\"padding\"], use_bias=d[\"use_bias\"]))\n",
    "    elif l == \"maxpool\":\n",
    "        model.add(layers.MaxPool2D(d[\"pool_size\"]))\n",
    "    elif l == \"flatten\":\n",
    "        model.add(layers.Flatten())\n",
    "    elif l == \"dense\":\n",
    "        model.add(layers.Dense(d[\"size\"], activation=d[\"activation\"]))\n",
    "    # elif l == \"output\":\n",
    "    #     model.add(layers.Dense(d[\"size\"], activation=d[\"activation\"])\n",
    "    else:\n",
    "        raise Exception(\"Invalid layer provided for the model\")\n",
    "        \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ccaf1d-2a4f-4a8d-888d-8b1062914be4",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### Step 3 - Part 2: Loading some image data and splitting into training and validation\n",
    "\n",
    "I don't want to use all of the available images to do some preliminary testing of model designs. Therefore, I'll setup some specific functions for training and validating on a small subset of the images available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "821666eb-9d00-4733-bb65-2a95f89380fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980 1020\n",
      "CPU times: total: 3.66 s\n",
      "Wall time: 9.74 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>493</td>\n",
       "      <td>50bd266a907e0a5c648e959277745ddde0b88993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270</td>\n",
       "      <td>8e72e27b0fb601c881ef84125bf25f51bdcdfa65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>482</td>\n",
       "      <td>2beb4425674591e7cf163717675f0a122e6541f3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>755</td>\n",
       "      <td>f4f1243220c1f51190c4f1c54a9ec5e47358ea63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496</td>\n",
       "      <td>0ace7ee78233ac5acd8d84d96a544a5248cb8de2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        id  label\n",
       "0    493  50bd266a907e0a5c648e959277745ddde0b88993      0\n",
       "1    270  8e72e27b0fb601c881ef84125bf25f51bdcdfa65      1\n",
       "2    482  2beb4425674591e7cf163717675f0a122e6541f3      1\n",
       "3    755  f4f1243220c1f51190c4f1c54a9ec5e47358ea63      1\n",
       "4    496  0ace7ee78233ac5acd8d84d96a544a5248cb8de2      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 3000 samples -> 9.91 s\n",
    "# 5000 samples -> 15.5 s\n",
    "\n",
    "X, X_ids, y_info = partial_load_data(3000)\n",
    "\n",
    "X_tr, y_tr, X_val, y_val = partial_train_val_split(X, y_info)\n",
    "\n",
    "#print(X_tr, y_tr, X_val, y_val)\n",
    "y_tr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51b84855-37ec-42de-b37e-aecc3dc1baa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             index        label\n",
      "count  1980.000000  1980.000000\n",
      "mean   1497.747475     0.388889\n",
      "std     875.370774     0.487621\n",
      "min       1.000000     0.000000\n",
      "25%     736.500000     0.000000\n",
      "50%    1501.500000     0.000000\n",
      "75%    2266.250000     1.000000\n",
      "max    2999.000000     1.000000 \n",
      "\n",
      "(96, 96, 3) \n",
      "\n",
      "(1020, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "## Just double-checking the X_tr, and X_val data\n",
    "print(y_tr.describe(),\"\\n\")\n",
    "#print(y_val.describe())\n",
    "print(X_tr[0,:,:,:].shape, \"\\n\")\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805dc61-fbe0-47b3-9dac-68795634378e",
   "metadata": {},
   "source": [
    "#### Step 3 - Part 3: Testing model parameters\n",
    "\n",
    "- [Done] Load some sample data\n",
    "- [Done] Create a consistent way to create CNN object\n",
    "- [*in progress*] Create function to perform final steps of model design\n",
    "- [*in progress*] Training and validation (I believe this is a TensorFlow built in function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62fbd14c-88ae-48fc-b330-517907f37816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compiler(model, opt_params, metrics):\n",
    "    opt = optimizers.SGD(learning_rate=opt_params[0],\n",
    "                         momentum=opt_params[1],\n",
    "                        name='SGD')\n",
    "    # \"from_logits=True\" -- recommended by tf documentation\n",
    "    model.compile(optimizer=opt,\n",
    "                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "149a8135-1e8a-4df8-9fe0-42e01d85ee33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_compiler(model, (0.001, 0.01), ['accuracy'])\n",
    "\n",
    "# testing something\n",
    "type(y_tr.loc[:,\"label\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f70324-e59e-42db-8d9d-a2bdc83456d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history is kind of like results!\n",
    "history = model.fit(X_tr,\n",
    "                    y_tr.loc[:,\"label\"].to_numpy(),\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_val, y_val.loc[:,\"label\"].to_numpy())\n",
    "                   )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

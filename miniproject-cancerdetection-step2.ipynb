{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Parker Dunn\n(pgdunn@bu.edu | pdunn91@gmail.com)  \nCreated on July 1st, 2022\n\n\n__Assignment for COURSERA: Introduction to Deep Learning (via CU Boulder)__\n\n__Assignment:__ Week 3 - CNN Cancer Detection Kaggle Mini-Project\n\n\n# Information about the Competition/Data\n___\n\nThe Kaggle competition is called \"Histopathologic Cancer Detection\"  \nLINK: https://www.kaggle.com/c/histopathologic-cancer-detection\n\n### Data Description (from Kaggle)\n\nIn this dataset, you are provided with a large number of small pathology images to classify. Files are named with an image id. The train_labels.csv file provides the ground truth for the images in the train folder. You are predicting the labels for the images in the test folder. A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label. This outer region is provided to enable fully-convolutional models that do not use zero-padding, to ensure consistent behavior when applied to a whole-slide image.\n\nThe original PCam dataset contains duplicate images due to its probabilistic sampling, however, the version presented on Kaggle does not contain duplicates. We have otherwise maintained the same data and splits as the PCam benchmark.","metadata":{}},{"cell_type":"markdown","source":"___\n# Imports","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# I moved imports below\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    print(dirname)\nprint(os.getcwd())\nos.listdir('/kaggle/input')\nos.listdir('/kaggle/input/histopathologic-cancer-detection')\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-13T18:48:10.752821Z","iopub.execute_input":"2022-07-13T18:48:10.753797Z","iopub.status.idle":"2022-07-13T18:48:10.768523Z","shell.execute_reply.started":"2022-07-13T18:48:10.753739Z","shell.execute_reply":"2022-07-13T18:48:10.767348Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from skimage import io\nimport pandas as pd\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#import multiprocessing\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:36:27.610653Z","iopub.execute_input":"2022-07-13T18:36:27.611083Z","iopub.status.idle":"2022-07-13T18:36:27.620654Z","shell.execute_reply.started":"2022-07-13T18:36:27.611046Z","shell.execute_reply":"2022-07-13T18:36:27.619423Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Below are functions used during Step 2","metadata":{}},{"cell_type":"code","source":"def load_image_info():\n    # get image filenames\n    \n    # train_locs = glob.glob(\"train/*.tif\")\n    # test_locs = glob.glob(\"test/*.tif\")\n    \n    #train_locs = glob.glob(\"data/train/*.tif\")\n    #test_locs = glob.glob(\"data/train/*.tif\")\n    \n    train_locs = glob.glob(\"/kaggle/input/histopathologic-cancer-detection/train/*.tif\")\n    test_locs = glob.glob(\"/kaggle/input/histopathologic-cancer-detection/test/*.tif\")\n    \n    num_train = len(train_locs)\n    num_test = len(test_locs)\n    \n    y_train = pd.read_csv(\"/kaggle/input/histopathologic-cancer-detection/train_labels.csv\", header=0)\n    \n    return train_locs, test_locs, y_train\n\ndef show_training_image(img_info):\n    # displaying the image\n    #file = \"train/\" + img_info.loc[\"id\"] + \".tif\"\n    file = \"/kaggle/input/histopathologic-cancer-detection/train/\"+img_info.loc[\"id\"]+\".tif\"\n    image = io.imread(file)\n    plt.imshow(image)\n    plt.title(\"{}\\n Class: {}\".format(img_info.loc[\"id\"], img_info.loc[\"label\"]))\n    \n    # Drawing the center 32x32 region on the picture\n    rectangle = plt.Rectangle((32,32), 32, 32, ec=\"red\", linewidth=1.5, fill=False)\n    plt.gca().add_patch(rectangle)\n    plt.legend([\"Classification Region\"])\n    \ndef show_training_images(img_info, dim):\n    fig, axes = plt.subplots(nrows=dim[0], ncols=dim[1], figsize=(10,8))\n    \n    ax = axes.flatten()\n    plt.subplots_adjust(hspace=0.4)\n    \n    for i in range(len(img_info.index)):\n        #file = \"train/\" + img_info.loc[i,\"id\"] + \".tif\"\n        file = \"/kaggle/input/histopathologic-cancer-detection/train/\"+img_info.loc[i,\"id\"]+\".tif\"\n        image = io.imread(file)\n        ax[i].imshow(image)\n        ax[i].set_title(\"{}\\n Class: {}\".format(img_info.loc[i,\"id\"], img_info.loc[i,\"label\"]))\n        rectangle = plt.Rectangle((32,32), 32, 32, ec=\"red\", linewidth=1.5, fill=False)\n        ax[i].add_patch(rectangle)\n        ax[i].legend([\"Classification Region\"])\n        \ndef load_image_data(img):\n    #file = \"train/\"+img+\".tif\"\n    #file = \"data/train/\"+img+\".tif\"\n    file = \"/kaggle/input/histopathologic-cancer-detection/train/\"+img+\".tif\"\n    image = io.imread(file)\n    return image\n\ndef calculate_img_avgs(images):\n    avg = np.zeros((96,96,3))\n    for img in images:\n        image_np = load_image_data(img)\n        avg = avg + image_np\n    avg = avg/len(images)\n    return avg","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:49:14.251188Z","iopub.execute_input":"2022-07-13T18:49:14.251561Z","iopub.status.idle":"2022-07-13T18:49:14.269032Z","shell.execute_reply.started":"2022-07-13T18:49:14.251531Z","shell.execute_reply":"2022-07-13T18:49:14.267895Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Step 2 - Exploratory Data Analysis (EDA)\n\n### Inspecting a single image","metadata":{}},{"cell_type":"code","source":"training_images, testing_images, y_train = load_image_info()\n\nprint(y_train.iloc[0,:])\nprint(type(y_train.iloc[0,:]),\"\\n\\n\")\n\nshow_training_image(y_train.iloc[0,:])","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:49:19.095207Z","iopub.execute_input":"2022-07-13T18:49:19.095765Z","iopub.status.idle":"2022-07-13T18:49:24.015708Z","shell.execute_reply.started":"2022-07-13T18:49:19.095732Z","shell.execute_reply":"2022-07-13T18:49:24.014868Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Inspecting multiple images","metadata":{}},{"cell_type":"code","source":"show_training_images(y_train.iloc[0:4,:], (2,2))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:50:17.598233Z","iopub.execute_input":"2022-07-13T18:50:17.598629Z","iopub.status.idle":"2022-07-13T18:50:18.258393Z","shell.execute_reply.started":"2022-07-13T18:50:17.598595Z","shell.execute_reply":"2022-07-13T18:50:18.257294Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Examining information distribution of the images\n\nHere, I looked at...\n* the \"average\" picture\n* comparison of purple color distributions","metadata":{}},{"cell_type":"code","source":"%%time\n\n# loop to collect averages of 100 images at a time\n# the 100 image avgs are saved in a list\navg_img_100 = []\nmoving_avg = np.zeros((96,96,3))\ncounter = 0\n\nfor i in range(len(y_train.index)):\n    if (i % 100 == 0) and (i != 0):\n        moving_avg = moving_avg/100\n        avg_img_100.append(moving_avg)\n        moving_avg = np.zeros((96,96,3))\n        counter = 0\n    if (i % 10000 == 0):\n        print(\"Progress...\")\n    \n    image = load_image_data(y_train.loc[i,\"id\"])\n    counter += 1\n    moving_avg = moving_avg + image\n\nif counter > 0:\n    print(\"End value of counter: \",counter)\n    avg_img_100.append(moving_avg/counter)\n\nprint(\"Number of NumPy arrays saved in avg_img_100: \", len(avg_img_100))\n# print(avg_img_100[0].shape)\n\n# getting the \"average image\" from the averages of 100 images\navg_img = np.zeros((96,96,3))\nfor i in range(len(avg_img_100)):\n    avg_img = avg_img + avg_img_100[i]\n\navg_img = avg_img/len(avg_img_100)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:15:52.660757Z","iopub.execute_input":"2022-07-13T19:15:52.661637Z","iopub.status.idle":"2022-07-13T19:42:11.708526Z","shell.execute_reply.started":"2022-07-13T19:15:52.661591Z","shell.execute_reply":"2022-07-13T19:42:11.706728Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"___\n__Alternate approach to loading the avg image data__  \n** Nevermind for now **","metadata":{}},{"cell_type":"code","source":"# processes = []\n# group_avgs = []\n# ii = 0\n\n# while ii < len(y_train.index):\n#     if len(processes) < 4: # then spawn a new process\n        \n#     else:\n#         for p in processes:\n#             p.join()\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"code","source":"savable_avg_img = avg_img.reshape(96*96,3)\n\nnp.savetxt(\"/kaggle/working/avg_training_image.txt\", savable_avg_img, delimiter=\",\")\n\nprint(\"Shape of 'avg_img': \", avg_img.shape)\nprint(\"\\nSample values...\\n\", avg_img[0:2,0:2,:])","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:42:29.223557Z","iopub.execute_input":"2022-07-13T19:42:29.225517Z","iopub.status.idle":"2022-07-13T19:42:29.292160Z","shell.execute_reply.started":"2022-07-13T19:42:29.225457Z","shell.execute_reply":"2022-07-13T19:42:29.290935Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Displaying the avg image\navg_img_int = avg_img.astype('int')\nplt.imshow(avg_img_int)\nplt.title(\"Average training image - Both Classes\")","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:43:03.766710Z","iopub.execute_input":"2022-07-13T19:43:03.767147Z","iopub.status.idle":"2022-07-13T19:43:03.970247Z","shell.execute_reply.started":"2022-07-13T19:43:03.767111Z","shell.execute_reply":"2022-07-13T19:43:03.968905Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Probably should have figured that the avg of all images would not be particularly helpful.\n\nI am curious to see if there is a difference between the average positive vs. negative image. I will basically repeat the same process once more; hopefully, there is some more useful information there.","metadata":{}},{"cell_type":"code","source":"%%time\n\n# loop to collect averages of 100 images at a time\n# the 100 image avgs are saved in a list\navg_img_pos = []\navg_img_neg = []\nmoving_avg_pos = np.zeros((96,96,3))\nmoving_avg_neg = np.zeros((96,96,3))\ncounter_pos = 0\ncounter_neg = 0\n\n# Simultaneous task -> track and save values for R & B channels of each image\npos_R = []\npos_B = []\nneg_R = []\nneg_B = []\n# End of setup for simultaneous task\n\nfor i in range(len(y_train.index)):\n    if (counter_pos == 1000):\n        moving_avg_pos = moving_avg_pos/counter_pos\n        avg_img_pos.append(moving_avg_pos)\n        moving_avg_pos = np.zeros((96,96,3))\n        counter_pos = 0\n    \n    if (counter_neg == 1000):\n        moving_avg_neg = moving_avg_neg/counter_neg\n        avg_img_neg.append(moving_avg_neg)\n        moving_avg_neg = np.zeros((96,96,3))\n        counter_neg = 0\n    \n    image = load_image_data(y_train.loc[i,\"id\"])\n    #print(image[:,:,0].shape)\n    \n    if (y_train.loc[i,\"label\"] == 1):\n        counter_pos += 1\n        moving_avg_pos = moving_avg_pos + image\n        \n        avg_R = image[:,:,0].reshape((1,-1)).mean()\n        avg_B = image[:,:,2].reshape((1,-1)).mean()\n        pos_R.append(avg_R)\n        pos_B.append(avg_B)\n    else:\n        counter_neg += 1\n        moving_avg_neg = moving_avg_neg + image\n        \n        avg_R = image[:,:,0].reshape((1,-1)).mean()\n        avg_B = image[:,:,2].reshape((1,-1)).mean()\n        neg_R.append(avg_R)\n        neg_B.append(avg_B)\n\nif (counter_pos > 0):\n    avg_img_pos.append(moving_avg_pos/counter_pos)\nif (counter_neg > 0):\n    avg_img_neg.append(moving_avg_neg/counter_neg)\n\navg_pos = np.zeros((96,96,3))\navg_neg = np.zeros((96,96,3))\n\n# POSITIVE IMAGES\nfor i in range(len(avg_img_pos)):\n    avg_pos = avg_pos + avg_img_pos[i]\navg_pos = avg_pos/len(avg_img_pos)\n\n# NEGATIVE IMAGES\nfor j in range(len(avg_img_neg)):\n    avg_neg = avg_neg + avg_img_neg[i]\navg_neg = avg_neg/len(avg_img_neg)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:43:15.195010Z","iopub.execute_input":"2022-07-13T19:43:15.195444Z","iopub.status.idle":"2022-07-13T19:58:12.059543Z","shell.execute_reply.started":"2022-07-13T19:43:15.195408Z","shell.execute_reply":"2022-07-13T19:58:12.058262Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Checking on my \"side-task\" data\nprint(\"posR \", len(pos_R), \"\\n\",\n      \"posB \", len(pos_B), \"\\n\",\n      \"negR \", len(neg_R), \"\\n\",\n      \"negB \", len(neg_B), \"\\n\")\n\n# Saving some data\n\npos_images_channel_vals = pd.DataFrame({'R':pos_R, 'B':pos_B})\nneg_images_channel_vals = pd.DataFrame({'R':neg_R, 'B':neg_B})\n\npos_images_channel_vals.to_csv(path_or_buf=\"/kaggle/working/positive_images_channel_vals.csv\")\nneg_images_channel_vals.to_csv(path_or_buf=\"/kaggle/working/negative_images_channel_vals.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-13T20:28:49.205317Z","iopub.execute_input":"2022-07-13T20:28:49.205813Z","iopub.status.idle":"2022-07-13T20:28:50.662541Z","shell.execute_reply.started":"2022-07-13T20:28:49.205772Z","shell.execute_reply":"2022-07-13T20:28:50.661193Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"for img, file in zip([avg_pos, avg_neg], [\"average_positive_image\", \"average_negative_image\"]):\n    print(file, img.shape)\n    #save_img_data(img, 96, file) - func wasn't working so I deleted\n    np.save(f\"/kaggle/working/{file}\", img)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T20:38:58.681362Z","iopub.execute_input":"2022-07-13T20:38:58.681836Z","iopub.status.idle":"2022-07-13T20:38:58.691431Z","shell.execute_reply.started":"2022-07-13T20:38:58.681798Z","shell.execute_reply":"2022-07-13T20:38:58.690338Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(12,10), sharey=True)\n\navg_pos_int = avg_pos.astype('int')\navg_neg_int = avg_neg.astype('int')\n\naxes[0].imshow(avg_pos_int)\naxes[0].set_title(\"Avg Positive Image\")\naxes[1].imshow(avg_neg_int)\naxes[1].set_title(\"Avg Negative Image\")","metadata":{"execution":{"iopub.status.busy":"2022-07-13T20:07:40.628272Z","iopub.execute_input":"2022-07-13T20:07:40.629177Z","iopub.status.idle":"2022-07-13T20:07:40.949148Z","shell.execute_reply.started":"2022-07-13T20:07:40.629131Z","shell.execute_reply":"2022-07-13T20:07:40.947866Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"There isn't much to take away from these images. Since they are averages over many images, they look mostly uniform.\n\nThere is a slight difference in the overall color and presentation of cell shapes in the images. The shade of purple of the average negative images appears to be slightly darker and more transparent. The average negative image also apperas to have some darker spots that are faintly identfiable.\n\nThe unhealthy cancer cells lose their distinct oval/circular shape. The distinction between the two images does suggest that the distince shape of the healthy cells is a fundamental feature of the images that can help me distiguish between the two classes of images.\n\n__Clearly, purple is the dominant color of these images (due to the staining process used for visualization). NEXT, I will compare how the component colors of purple (red and blue) compare between the positive and negative images.__","metadata":{}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nlight_blue=\"#ADD8E6\"\nlight_red='#FFCCCB'\n\nfig, axes = plt.subplots(ncols=2, nrows=2, figsize=(12,10), sharey=True)\nplt.subplots_adjust(hspace=0.4)\n\naxes[0,0].set_title(\"Positive Images - Red\")\naxes[0,0].set_xlabel(\"Avg Pixel Value (0 - 255)\",fontsize=\"small\")\naxes[0,0].set_ylabel(\"Count\", fontsize=\"small\")\naxes[0,0].set_xlim(left=0,right=255)\naxes[0,0].hist(pos_R, 20, range=(0,255), color=light_red)\n\naxes[0,1].set_title(\"Positive Images - Blue\")\naxes[0,1].set_xlabel(\"Avg Pixel Value (0 - 255)\",fontsize=\"small\")\naxes[0,1].set_ylabel(\"Count\", fontsize=\"small\")\naxes[0,1].set_xlim(left=0,right=255)\naxes[0,1].hist(pos_B, 20, range=(0,255), color=light_blue)\n\naxes[1,0].set_title(\"Negative Images - Red\")\naxes[1,0].set_xlabel(\"Avg Pixel Value (0 - 255)\",fontsize=\"small\")\naxes[1,0].set_ylabel(\"Count\", fontsize=\"small\")\naxes[1,0].set_xlim(left=0,right=255)\naxes[1,0].hist(neg_R, 20, range=(0,255), color=light_red)\n\naxes[1,1].set_title(\"Negative Images - Blue\")\naxes[1,1].set_xlabel(\"Avg Pixel Value (0 - 255)\",fontsize=\"small\")\naxes[1,1].set_ylabel(\"Count\", fontsize=\"small\")\naxes[1,1].set_xlim(left=0,right=255)\naxes[1,1].hist(neg_B, 20, range=(0,255), color=light_blue)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T21:12:17.479215Z","iopub.execute_input":"2022-07-13T21:12:17.479679Z","iopub.status.idle":"2022-07-13T21:12:20.429866Z","shell.execute_reply.started":"2022-07-13T21:12:17.479640Z","shell.execute_reply":"2022-07-13T21:12:20.428701Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"The faint shapes of the average negative image above show up here a little bit. The distribution of purple in the negative images appears to be bimodal, but the positive images resemble a normal distribution. When comparing to the average images above, it is important to note that these histograms are averaged across all the pixels of an image. The average images, however, are averaged across all images and show average data for each pixel.\n\nThe histograms suggest that there are two different \"average\" hues of purple among the negative images, while the positive images tend to average out to similar hues of purple. Since the averages of both channels in the negative and positive images appear to be in similar locations, the color distribution does not really provide a way to distiguish between the two classes consistently. The distributions may suggest something about the colors of the features/objects in the images though, which hopefully the CNN model can identify.\n\n\n### One thing that I did not do...\n\nThe histograms above are really an amalgamation of lots of pixel information. When generating the data, the R and B channels of each image were averaged across an entire image then saved. It would be interesting to investigate/generate histograms of the R and B channels for each pixel across all images. Or, even better, useful information might be available by looking at the avg. value of the R & B channels across sections of the images. These histograms would reveal more detailed information about distribution of objects in the images, which is essentially removed in the plots above because of averaging across an entire image.\n\nBy implementing a convolutional neural network, hopefully, the object level information can be extracted better than the plots created above.","metadata":{}}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45fa3a83-5465-4bde-806d-aaf30e9c0343",
   "metadata": {},
   "source": [
    "# Parker Dunn\n",
    "(pgdunn@bu.edu | pdunn91@gmail.com)  \n",
    "Created on July 1st, 2022\n",
    "\n",
    "\n",
    "__Assignment for COURSERA: Introduction to Deep Learning (via CU Boulder)__\n",
    "\n",
    "__Assignment:__ Week 3 - CNN Cancer Detection Kaggle Mini-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63044cb1-bb5f-43aa-8c54-336d48380e3b",
   "metadata": {},
   "source": [
    "## Progress...\n",
    "[*in progress*] Step 1 - Description of the data and problem  \n",
    "[*in progress*] Step 2 - EDA  \n",
    "[ _ ] Step 3 -  \n",
    "[ _ ] Step 4 -  \n",
    "[ _ ] Step 5 -  \n",
    "[ _ ] Step 6 -  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d311a-64d1-472d-b034-0a554fb53d23",
   "metadata": {},
   "source": [
    "# Information about the Competition/Data\n",
    "___\n",
    "\n",
    "The Kaggle competition is called \"Histopathologic Cancer Detection\"  \n",
    "LINK: https://www.kaggle.com/c/histopathologic-cancer-detection\n",
    "\n",
    "### Data Description (from Kaggle)\n",
    "\n",
    "In this dataset, you are provided with a large number of small pathology images to classify. Files are named with an image id. The train_labels.csv file provides the ground truth for the images in the train folder. You are predicting the labels for the images in the test folder. A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label. This outer region is provided to enable fully-convolutional models that do not use zero-padding, to ensure consistent behavior when applied to a whole-slide image.\n",
    "\n",
    "The original PCam dataset contains duplicate images due to its probabilistic sampling, however, the version presented on Kaggle does not contain duplicates. We have otherwise maintained the same data and splits as the PCam benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faac8c65-5920-45c8-9d2f-5c9638e9f116",
   "metadata": {},
   "source": [
    "___\n",
    "# My work starts here\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e416f75d-0b73-4c54-b410-85e7df4a98bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (helperfunctions.py, line 18)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3398\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m in \u001b[1;35m<cell line: 6>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from helperfunctions import *\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\OneDrive\\Documents\\4-Code\\IntroToDL_CancerMiniProject\\helperfunctions.py:18\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\" Above is supposed to be based on below\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# imports of packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from helperfunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2800b6d-ed2b-420e-8379-e1c50edaa521",
   "metadata": {},
   "source": [
    "## Step 1 - Description of the data and problem\n",
    "\n",
    "For this project, originally a Kaggle competition, the task is to identify images of cells that contain metastatic cancer. This is a binary classification task on images. If an image contains at least one pixel of tumor tissue within a specified region, it is given a positive label. The images are 96x96 pixels, but the specific region used to classify the images is the center 32x32 pixel region. The task is setup this way to enable fully-convolutional models that do not use padding.\n",
    "\n",
    "The data for this task is provided as 96x96x3 images, which are small parts of larger images. This means there are 27,648 total features for each image, including the three RGB channels and all 9,216 pixels in the image. Each pixel is provided as three RGB values from 0 to 255.\n",
    "\n",
    "There are 277,483 images provided for this task. The images are divided into 220,025 images for training, since the corresponding labels are provided, and 57,458 images without provided labels. For these test images, a model will try to correctly predict whether these images have (1) or do not have (0) metastatic cancer cells.\n",
    "\n",
    "Summary:\n",
    "* 96x96x3 dimensions for each image -> 27,648 features initially\n",
    "* 220,025 images in training set\n",
    "* TRAINING: 27648 features x 220,025 images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529ea44-8f72-4827-8cfc-a33fffc2467a",
   "metadata": {},
   "source": [
    "## Step 2 - Exploratory Data Analysis (EDA)\n",
    "\n",
    "#### Functions for previewing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11ccd77-b757-4dda-9520-c768350bc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(X, i):\n",
    "    # select image\n",
    "    image = X[i,:]\n",
    "    # reshape into original image structure (32 x 32)\n",
    "    image = image.reshape((32,32))\n",
    "    # display the image\n",
    "    plt.imshow(image)\n",
    "    \n",
    "def show_images(X, dim, lst):\n",
    "    fig, axes = plt.subplots(nrows=dim[0], ncols=dim[1], figsize=(10, 8))\n",
    "    \n",
    "    images = []\n",
    "    for img in lst:\n",
    "        image = X[img, :]\n",
    "        image.reshape((32,32))\n",
    "        images.append(image) # assumes each image is a row in X\n",
    "    \n",
    "    for ax, image in zip(axes.flatten(), images):\n",
    "        ax.imshow(image)   # I think this is all that is needed to produce the image\n",
    "                            # additional arguments allow me to modify the images though\n",
    "        ax.set_xticks(list(range(0,32,1)))\n",
    "        ax.set_yticks(list(range(0,32,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9dee8-90e6-42aa-9069-84c50d2c7e80",
   "metadata": {},
   "source": [
    "#### Inspecting the images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
